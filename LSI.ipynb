{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from gensim.models.word2vec import Word2Vec as W2V\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "import os.path\n",
    "from gensim import corpora, similarities\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from matplotlib.pyplot import figure as fg\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatasetLoad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_names = ['stem_text', 'doc_text', 'lem_text']\n",
    "df_col_select = df_col_names[0]\n",
    "df_query_col_names = ['cl_q', 'stem_q', 'lem_q']\n",
    "df_query_col_select = df_query_col_names[0]\n",
    "test_dim = 0.2\n",
    "print(\"\\nTEXT: \" + df_col_select + \"\\nQUERY: \" + df_query_col_select + \"\\nTEST_DIM: \" + str(test_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Docs/\"\n",
    "luc_retr = path+\"raw_dev_Lucene_retrievals.csv\"\n",
    "g_truth_rank = path + \"dev_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cl = \"ProcDocs/Split_\"+str(test_dim)+\"/\"\n",
    "docs_test_path = path_cl +\"docs_test.csv\"\n",
    "docs_train_path = path_cl +\"docs_train.csv\"\n",
    "queries_test_path = path_cl +\"queries_test.csv\"\n",
    "queries_train_path = path_cl +\"queries_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ProcDocs/LSI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train_df = pd.read_csv(docs_train_path)\n",
    "docs_test_df = pd.read_csv(docs_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_train_df = pd.read_csv(queries_train_path)\n",
    "queries_test_df = pd.read_csv(queries_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luc_retr_df = pd.read_csv(luc_retr)\n",
    "g_truth_r = pd.read_csv(g_truth_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    \"\"\"\n",
    "    Input  : clean document\n",
    "    Purpose: create term dictionary of our courpus and Converting list of documents (corpus) into Document Term Matrix\n",
    "    Output : term dictionary and Document Term Matrix\n",
    "    \"\"\"\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    tfidf = TfidfModel(doc_term_matrix)\n",
    "    corpus_tfidf = tfidf[doc_term_matrix]\n",
    "\n",
    "    # generate LDA model\n",
    "    return dictionary, corpus_tfidf, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input   : dictionary : Gensim dictionary\n",
    "              corpus : Gensim corpus\n",
    "              texts : List of input texts\n",
    "              stop : Max num of topics\n",
    "    purpose : Compute c_v coherence for various number of topics\n",
    "    Output  : model_list : List of LSA topic models\n",
    "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for number_of_topics in tqdm(range(start, stop, step)):\n",
    "        # generate LSA model\n",
    "        model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_tok=list(docs_train_df[df_col_select].apply(lambda x: str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 5\n",
    "dictionary,doc_term_matrix, tfidf=prepare_corpus(clean_text_tok)\n",
    "model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(q_num, df_result):\n",
    "    comparison = g_truth_r.loc[(g_truth_r.Query_number == q_num), ['Query_number', 'doc_number', 'label']].reset_index(drop=True)\n",
    "    comparison = comparison[comparison.label == 1]\n",
    "    n_tot_corr = len(comparison)\n",
    "    df_result = df_result.iloc[:n_tot_corr]\n",
    "    score = []\n",
    "    score_pos = []\n",
    "    \n",
    "    for i in range(1,n_tot_corr):\n",
    "        if int(df_result.iloc[i-1]['doc_number']) in list(comparison['doc_number']):\n",
    "            score.append(1)\n",
    "            score_pos.append((np.sum(score)/i))\n",
    "        else:\n",
    "            score.append(0)\n",
    "    if np.sum(score) == 0:\n",
    "        return 0\n",
    "    return np.sum(score_pos)/len(score_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at(q_num, df_result, rec_at=20):\n",
    "    comparison = g_truth_r.loc[(g_truth_r.Query_number == q_num), ['Query_number', 'doc_number']].reset_index(drop=True)\n",
    "    n_tot_corr = min(rec_at, len(comparison)) \n",
    "    df_result = df_result.iloc[:n_tot_corr]\n",
    "    score = []\n",
    "    for i in range(1,n_tot_corr):\n",
    "        if int(df_result.iloc[i-1]['doc_number']) == int(comparison.iloc[i-1]['doc_number']):\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    if np.sum(score) == 0:\n",
    "        return 0\n",
    "    return np.sum(score)/n_tot_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_docs_ranker(q_num, model, rec_at = [10]):\n",
    "    #Selected query: true documents ids\n",
    "    s_q_true = g_truth_r.loc[g_truth_r.Query_number == q_num, ['Query_number', 'doc_number']].reset_index(drop=True)\n",
    "    #Selected query text\n",
    "    s_query = queries_test_df.loc[queries_test_df.Query_number == q_num].reset_index(drop=True)\n",
    "\n",
    "    #Selected query: true documents\n",
    "    used_docs_query = docs_test_df[docs_test_df.doc_number.isin(list(s_q_true.doc_number))].reset_index(drop=True)\n",
    "\n",
    "    doc_num = list(used_docs_query['doc_number'])\n",
    "    #Used documents text\n",
    "    used_docs_list = list(used_docs_query[df_col_select].apply(lambda x: str(x).split()))\n",
    "    _, used_docs_matr,_ = prepare_corpus(used_docs_list)\n",
    "\n",
    "    # convert the query to LSI space\n",
    "    doc = s_query[df_query_col_select].values[0]\n",
    "    vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "    vec_bow_tfidf = tfidf[vec_bow]\n",
    "    vec_lsi = model[vec_bow_tfidf]  \n",
    "\n",
    "    index = similarities.MatrixSimilarity(model[used_docs_matr]) \n",
    "\n",
    "    # perform a similarity query against the corpus\n",
    "    sims = index[vec_lsi]  \n",
    "\n",
    "    sims_1 = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    df_result = pd.DataFrame(columns=['doc_number', 'sim'])\n",
    "    for doc_position, doc_score in sims_1:\n",
    "        df_result = df_result.append({'doc_number': int(doc_num[doc_position]),'sim': doc_score}, ignore_index = True)\n",
    "\n",
    "    rec_0 = recall_at(q_num, df_result, rec_at=rec_at[0])\n",
    "    rec_1 = recall_at(q_num, df_result, rec_at=rec_at[1])\n",
    "    rec_2 = recall_at(q_num, df_result, rec_at=rec_at[2])\n",
    "    ai_OR= average_precision(q_num, df_result)\n",
    "        \n",
    "    return [rec_0,rec_1,rec_2, ai_OR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = queries_test_df.Query_number.progress_apply(lambda x: query_docs_ranker(x, model, rec_at=[5,10,20])).to_list()\n",
    "score_df = pd.DataFrame(tmp)\n",
    "print(\"rec@5: \"+str(np.mean(score_df.iloc[:,0].to_list())*100))\n",
    "print(\"rec@10: \"+str(np.mean(score_df.iloc[:,1].to_list())*100))\n",
    "print(\"rec@20: \"+str(np.mean(score_df.iloc[:,2].to_list())*100))\n",
    "print(\"avg_p: \"+str(np.mean(score_df.iloc[:,3].to_list())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_tok=list(docs_train_df[df_col_select].apply(lambda x: str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary,doc_term_matrix, tfidf=prepare_corpus(clean_text_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_d = dict()\n",
    "coherence_values_d = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = list(range(3, 41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(k_test):\n",
    "    start,stop,step=x, x+1, 1\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix,clean_text_tok, stop, start, step)\n",
    "    model_list_d[x] = model_list[0]\n",
    "    coherence_values_d[x] = coherence_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_list_d[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify num of topics with coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_coherence_values_d = []\n",
    "for x in k_test:\n",
    "    ordered_coherence_values_d.append(coherence_values_d[x])\n",
    "fg(figsize=(11, 10), dpi=80)\n",
    "plt.plot(k_test, ordered_coherence_values_d)\n",
    "plt.vlines(np.arange(k_test[0],k_test[len(k_test)-1],1), -3, 0, color = 'grey', linestyle = \"--\")\n",
    "plt.xticks(np.arange(k_test[0],k_test[len(k_test)-1],1))\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify num of topics with k-maens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Source: https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in k_test:\n",
    "    x = model_list_d[key]\n",
    "    topic_weights = []\n",
    "    for i, row_list in enumerate(x[doc_term_matrix]):\n",
    "        topic_weights.append([w for i, w in row_list])\n",
    "    # Array of topic weights    \n",
    "    arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "    # Keep the well separated points (optional)\n",
    "    arr = arr[np.amax(arr, axis=1) > 0.10]\n",
    "    # Dominant topic number in each doc\n",
    "    topic_num = np.argmax(arr, axis=1)\n",
    "    # tSNE Dimension Reduction\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "    tsne_lda = tsne_model.fit_transform(arr)\n",
    "    x1 = np.array(tsne_lda[:,0])\n",
    "    x2 = np.array(tsne_lda[:,1])\n",
    "    X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)\n",
    "    X_list.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load reduced dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_fix = model_path+\"param_opt\"\n",
    "np.save(model_path+\"param_opt/red_dim.npy\",np.array(X_list, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_fix = model_path+\"param_opt\"\n",
    "X_list = list(np.load(model_path+\"param_opt/red_dim.npy\", allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "inertias = []\n",
    "mapping1 = {}\n",
    "mapping2 = {}\n",
    "K = k_test\n",
    " \n",
    "for k in K:\n",
    "    # Building and fitting the model\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X_list[k-3])\n",
    "    kmeanModel.fit(X_list[k-3])\n",
    " \n",
    "    distortions.append(sum(np.min(cdist(X_list[k-3], kmeanModel.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / X_list[k-3].shape[0])\n",
    "    inertias.append(kmeanModel.inertia_)\n",
    " \n",
    "    mapping1[k] = sum(np.min(cdist(X_list[k-3], kmeanModel.cluster_centers_,\n",
    "                                   'euclidean'), axis=1)) / X_list[k-3].shape[0]\n",
    "    mapping2[k] = kmeanModel.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg(figsize=(13, 13), dpi=100)\n",
    "plt.vlines(np.arange(0,k_test[len(k_test)-1],1), 0, 23, color = 'grey', linestyle = \"--\", alpha = 0.3)\n",
    "plt.vlines([11], 0, distortions[8], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([16], 0, distortions[13], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([35], 0, distortions[32], color = 'red', linestyle = \"--\")\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.subplot().axline((11, distortions[8]), (14, distortions[11]), color='orange', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((16, distortions[13]), (25, distortions[22]), color='green', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((35, distortions[32]), (40, distortions[37]), color='brown', label='by points', linestyle = \"--\")\n",
    "plt.xticks(np.arange(0,k_test[len(k_test)-1],1))\n",
    "plt.yticks(np.arange(0,23,1))\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.legend([\"Distortion\", \"loc@11\", \"loc@16\", \"loc@35\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = list(map(lambda i: i/1000000, inertias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg(figsize=(13, 13), dpi=100)\n",
    "plt.vlines(np.arange(0,k_test[len(k_test)-1],1), 0, 5, color = 'grey', linestyle = \"--\", alpha = 0.3)\n",
    "plt.vlines([11], 0, inertias[8], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([16], 0, inertias[13], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([35], 0, inertias[32], color = 'red', linestyle = \"--\")\n",
    "plt.plot(K, inertias, 'bx-')\n",
    "plt.subplot().axline((11, inertias[8]), (14, inertias[11]), color='orange', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((16, inertias[13]), (25, inertias[22]), color='green', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((35, inertias[32]), (40, inertias[37]), color='brown', label='by points', linestyle = \"--\")\n",
    "plt.xticks(np.arange(0,k_test[len(k_test)-1],1))\n",
    "plt.yticks(np.arange(0,6,1))\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.legend([\"Ineritias\", \"loc@11\", \"loc@16\", \"loc@35\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(k_test):\n",
    "    end_fix = model_path+\"param_opt\"\n",
    "    end_fix = end_fix+\"/LSI_model_\"+str(x)\n",
    "    try: \n",
    "        os.mkdir(end_fix)\n",
    "    except:\n",
    "        continue\n",
    "    model_list_d[x].save(end_fix + \"/mod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads models if previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(k_test):\n",
    "    end_fix = model_path+\"param_opt\"\n",
    "    end_fix = end_fix+\"/LSI_model_\"+str(x)\n",
    "    model_list_d[x] = LsiModel.load(end_fix + \"/mod\")\n",
    "    coherence_values_d[x] = CoherenceModel(model=model_list_d[x], texts=clean_text_tok, dictionary=dictionary, coherence='u_mass').get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_list_d[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE Plot from: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_lda_16 = tsne_lda\n",
    "topic_num_16 = topic_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for j, row_list in enumerate(model[doc_term_matrix]):\n",
    "    topic_weights.append([w for i, w in row_list])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.1]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 11\n",
    "mycolors = np.array([color for name, color in mcolors.CSS4_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), plot_width=600, plot_height=600)\n",
    "mycolors = np.array(sns.color_palette(n_colors=40).as_hex())\n",
    "random.shuffle(mycolors)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg(figsize=(13, 13), dpi=100)\n",
    "plt.vlines(np.arange(0,k_test[len(k_test)-1],1), 0, 5, color = 'grey', linestyle = \"--\", alpha = 0.3)\n",
    "plt.vlines([11], 0, inertias[8], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([16], 0, inertias[13], color = 'red', linestyle = \"--\")\n",
    "plt.vlines([35], 0, inertias[32], color = 'red', linestyle = \"--\")\n",
    "plt.plot(K, inertias, 'bx-')\n",
    "plt.subplot().axline((11, inertias[8]), (14, inertias[11]), color='orange', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((16, inertias[13]), (25, inertias[22]), color='green', label='by points', linestyle = \"--\")\n",
    "plt.subplot().axline((35, inertias[32]), (40, inertias[37]), color='brown', label='by points', linestyle = \"--\")\n",
    "plt.xticks(np.arange(0,k_test[len(k_test)-1],1))\n",
    "plt.yticks(np.arange(0,6,1))\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.legend([\"Ineritias\", \"loc@11\", \"loc@16\", \"loc@35\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg(figsize=(8, 8), dpi=80)\n",
    "x = np.arange(4)\n",
    "avg = [76.37, 76.80, 74.29, 59.30]\n",
    "width = 0.5\n",
    "  \n",
    "# plot data in grouped manner of bar type\n",
    "plt.bar(x, avg, width)\n",
    "plt.xticks(x, ['Skip-Gram', 'CBOW', 'CADE-CBOW', 'LSI'])\n",
    "plt.yticks(np.arange(0,101,10))\n",
    "plt.ylabel('Avg Precision %')\n",
    "plt.legend([\"Average Precision\"])\n",
    "for i in range(len(x)):\n",
    "    plt.text(i-0.15, avg[i]/2, str(avg[i]) + '%', color='orange', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg(figsize=(8, 8), dpi=80)\n",
    "x = np.arange(4)\n",
    "y5 = [10.1,9.1, 10.4, 3.5]\n",
    "y10 = [7.90, 6.89, 7.51, 3.9]\n",
    "width = 0.40\n",
    "  \n",
    "# plot data in grouped manner of bar type\n",
    "plt.bar(x-0.2, y5, width)\n",
    "plt.bar(x+0.2, y10, width)\n",
    "plt.xticks(x, ['Skip-Gram', 'CBOW', 'CADE-CBOW', 'LSI'])\n",
    "plt.ylabel('Recall %')\n",
    "plt.legend([\"Rec@5\", \"Rec@10\"])\n",
    "for i in range(len(x)):\n",
    "    plt.text(i-0.31, y5[i]/2, str(y5[i]) + '%', color='orange', fontweight='bold')\n",
    "    plt.text(i+0.06, y10[i]/2, str(y10[i]) + '%', color='blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19649b6d477f04954267d7dfcc1e3219afd53992c8847ec6a09d5cd5145b7914"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
